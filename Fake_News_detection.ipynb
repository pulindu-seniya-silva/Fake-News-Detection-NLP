{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1b1RikSw2aIISShPkMvK82I9Utk9oo3YK",
      "authorship_tag": "ABX9TyPfgARr4Pt2E0hFCirOjh/t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pulindu-seniya-silva/Fake-News-Detection-NLP/blob/main/Fake_News_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U7UuaYXYLYjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c7ce418-b45d-42a0-d008-ac846a38ecb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "#installing NLTK for text preprocessing\n",
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #install Hugging Face 'transformers' library for BERT/deep Learning\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98bp9Wvliqfw",
        "outputId": "e0d65eef-9b1c-4ba2-d8b9-9a8ba72aabb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset"
      ],
      "metadata": {
        "id": "UPVUUeXcPGwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Data Manipulation and Exploration\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "# Mount Google Drive (if the file is there)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/fake_news_dataset.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2XRcsdHrIMg",
        "outputId": "4bd14dab-20e0-4573-d1c6-9e181342d116"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "                                  title  \\\n",
            "0               Foreign Democrat final.   \n",
            "1   To offer down resource great point.   \n",
            "2          Himself church myself carry.   \n",
            "3                  You unit its should.   \n",
            "4  Billion believe employee summer how.   \n",
            "\n",
            "                                                text        date    source  \\\n",
            "0  more tax development both store agreement lawy...  2023-03-10  NY Times   \n",
            "1  probably guess western behind likely next inve...  2022-05-25  Fox News   \n",
            "2  them identify forward present success risk sev...  2022-09-01       CNN   \n",
            "3  phone which item yard Republican safe where po...  2023-02-07   Reuters   \n",
            "4  wonder myself fact difficult course forget exa...  2023-04-03       CNN   \n",
            "\n",
            "                 author    category label  \n",
            "0          Paula George    Politics  real  \n",
            "1           Joseph Hill    Politics  fake  \n",
            "2        Julia Robinson    Business  fake  \n",
            "3  Mr. David Foster DDS     Science  fake  \n",
            "4         Austin Walker  Technology  fake  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nDataset Info:\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI9PpsgdOqwG",
        "outputId": "8e4682e0-f4b5-4fff-8efd-b8ffb94e6674"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   title     20000 non-null  object\n",
            " 1   text      20000 non-null  object\n",
            " 2   date      20000 non-null  object\n",
            " 3   source    19000 non-null  object\n",
            " 4   author    19000 non-null  object\n",
            " 5   category  20000 non-null  object\n",
            " 6   label     20000 non-null  object\n",
            "dtypes: object(7)\n",
            "memory usage: 1.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "#Natural Language Processing (Text Cleaning and Preprocessing)\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "#Machine Learning (Feature Extraction and Models)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "#Downloard NLTK resources\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "-aqUv-7YQATj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8426ae9a-2d3a-4e02-ecec-b0d99b4ca3ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminary Data Inspection"
      ],
      "metadata": {
        "id": "_7C34RcnbiZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check the total number of rows and columns\n",
        "print(f\"\\nTotal rows and columns: {df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWxM7hYVa__V",
        "outputId": "b004dba2-4b58-4d6c-d90b-60d54983a7fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total rows and columns: (20000, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for missing values in each column\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s35Ts_6bcHWK",
        "outputId": "6c5ca52b-90e8-4041-f7d2-2f4d46d1df2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values per column:\n",
            "title          0\n",
            "text           0\n",
            "date           0\n",
            "source      1000\n",
            "author      1000\n",
            "category       0\n",
            "label          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# imputation (Handling Missing Vlaues)"
      ],
      "metadata": {
        "id": "90dgiGrjdy50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fill Nan values in 'author' and 'source' columns with 'Unknow'\n",
        "df['author'] = df['author'].fillna('Unknow')\n",
        "df['source'] = df['source'].fillna('Unknow')\n",
        "\n",
        "#Re-check for nulls to confirm\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(df.isnull().sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVo9h3OZd2Un",
        "outputId": "40015d3c-7dcf-4533-a19e-ccd47b872817"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values after imputation:\n",
            "<bound method DataFrame.sum of        title   text   date  source  author  category  label\n",
            "0      False  False  False   False   False     False  False\n",
            "1      False  False  False   False   False     False  False\n",
            "2      False  False  False   False   False     False  False\n",
            "3      False  False  False   False   False     False  False\n",
            "4      False  False  False   False   False     False  False\n",
            "...      ...    ...    ...     ...     ...       ...    ...\n",
            "19995  False  False  False   False   False     False  False\n",
            "19996  False  False  False   False   False     False  False\n",
            "19997  False  False  False   False   False     False  False\n",
            "19998  False  False  False   False   False     False  False\n",
            "19999  False  False  False   False   False     False  False\n",
            "\n",
            "[20000 rows x 7 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nHnnc_i8ga0U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}